{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6604f8e3-990b-4ef8-9d0c-62b139aeb8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47ddaed0-8400-42e7-b198-1b4dc9ad0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/credit_card_fraud_dataset.csv\")\n",
    "df = df.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "642f01e5-3b9d-4eb0-8360-98fdecf23221",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"IsFraud\", axis=1)\n",
    "y = df[\"IsFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdc08c7f-9fe1-4af2-86e5-210bf7432015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83f864b4-bcd9-49d2-a855-8bead192a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1788c03d-544c-4cf0-a4b3-e1223e8319b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedF1(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='weighted_f1', **kwargs):\n",
    "        super(WeightedF1, self).__init__(name=name, **kwargs)\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(tf.greater(y_pred, 0.5), tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "\n",
    "        tp = tf.reduce_sum(tf.cast(y_true * y_pred, self.dtype))\n",
    "        fp = tf.reduce_sum(tf.cast((1 - y_true) * y_pred, self.dtype))\n",
    "        fn = tf.reduce_sum(tf.cast(y_true * (1 - y_pred), self.dtype))\n",
    "\n",
    "        self.tp.assign_add(tp)\n",
    "        self.fp.assign_add(fp)\n",
    "        self.fn.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + 1e-7)\n",
    "        recall = self.tp / (self.tp + self.fn + 1e-7)\n",
    "        return 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f3ba80e-9d59-4802-8efb-33877b1c9240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\indum\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', WeightedF1()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35244810-5914-4a59-a06e-dd69abeca885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9413 - loss: 0.4964 - weighted_f1: 0.0113 - val_accuracy: 0.9898 - val_loss: 0.2659 - val_weighted_f1: 0.0000e+00\n",
      "Epoch 2/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9895 - loss: 0.2180 - weighted_f1: 0.0000e+00 - val_accuracy: 0.9898 - val_loss: 0.1162 - val_weighted_f1: 0.0000e+00\n",
      "Epoch 3/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9902 - loss: 0.1011 - weighted_f1: 0.0000e+00 - val_accuracy: 0.9898 - val_loss: 0.0761 - val_weighted_f1: 0.0000e+00\n",
      "Epoch 4/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0727 - weighted_f1: 0.0000e+00 - val_accuracy: 0.9898 - val_loss: 0.0661 - val_weighted_f1: 0.0000e+00\n",
      "Epoch 5/5\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9898 - loss: 0.0645 - weighted_f1: 0.0000e+00 - val_accuracy: 0.9898 - val_loss: 0.0633 - val_weighted_f1: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x212799d7a10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=2048, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7f50a9f-5fec-407c-bd2b-66869742d204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\indum\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f768e579-0b8b-4814-83be-63a41a66ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = np.sum((y_test.values == 1) & (y_pred.flatten() == 1))\n",
    "fp = np.sum((y_test.values == 0) & (y_pred.flatten() == 1))\n",
    "fn = np.sum((y_test.values == 1) & (y_pred.flatten() == 0))\n",
    "custom_f1 = 2 * tp / (2 * tp + fp + fn + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2212411a-b8cf-4fdc-bc7b-9825f43765b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Metric Comparison Table:\n",
      "Metric              Value     \n",
      "------------------------------\n",
      "Accuracy            0.9900\n",
      "Standard F1         0.0000\n",
      "Custom Weighted F1  0.0000\n",
      "\n",
      "🧠 Custom Metric Insight:\n",
      "The custom weighted F1 score balances precision and recall, especially valuable in imbalanced datasets like fraud detection.\n",
      "It helps evaluate performance beyond mere accuracy, which can be misleading when classes are imbalanced.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n📊 Metric Comparison Table:\")\n",
    "print(f\"{'Metric':<20}{'Value':<10}\")\n",
    "print(f\"{'-'*30}\")\n",
    "print(f\"{'Accuracy':<20}{model.evaluate(X_test, y_test, verbose=0)[1]:.4f}\")\n",
    "print(f\"{'Standard F1':<20}{f1:.4f}\")\n",
    "print(f\"{'Custom Weighted F1':<20}{custom_f1:.4f}\")\n",
    "print(\"\\n🧠 Custom Metric Insight:\")\n",
    "print(\"The custom weighted F1 score balances precision and recall, especially valuable in imbalanced datasets like fraud detection.\")\n",
    "print(\"It helps evaluate performance beyond mere accuracy, which can be misleading when classes are imbalanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa395ab-43d8-4c8f-ad45-c32a1ac83e41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
